{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7Xs1S3VcjVRk"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpEiOePhjVRo"
   },
   "outputs": [],
   "source": [
    "def createBaskets(sourceFile, destFile):\n",
    "    tsv = csv.reader(open(sourceFile, encoding=\"utf-8\"), delimiter=\"\\t\")\n",
    "    print(sys.getsizeof(tsv))\n",
    "    c=0\n",
    "    keys = []\n",
    "    baskets = []\n",
    "    items = []\n",
    "    for row in tsv:\n",
    "        if row[3]==\"actor\" or row[3]==\"actress\":\n",
    "            \n",
    "            if row[2] not in items:\n",
    "                items.append(row[2])\n",
    "            pos = items.index(row[2])\n",
    "            \n",
    "            if row[0] in keys:\n",
    "                baskets[keys.index(row[0])] += [pos]\n",
    "            else:\n",
    "                keys += [row[0]]\n",
    "                baskets.append([pos])\n",
    "            if c==1000:\n",
    "                break;\n",
    "            c = c+1\n",
    "#     return keys, baskets\n",
    "    with open(destFile+\".csv\",\"w\") as f:\n",
    "        wr = csv.writer(f,delimiter=\";\")\n",
    "        for el in baskets:\n",
    "            wr.writerow(el)\n",
    "    with open(\"actorIdToInt.csv\",\"w\") as f:\n",
    "        wr = csv.writer(f,delimiter=\";\")\n",
    "        for el in items:\n",
    "            wr.writerow([el])\n",
    "    #json.dump(baskets, open(destFile+'.json', 'w'))\n",
    "    #json.dump(keys, open('actorIdToInt.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lza-t6UhjVRr",
    "outputId": "dee7a29a-a486-417a-8c17-302da501a756"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "createBaskets(\"data.tsv\", \"preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqIy5YOPjVRt",
    "outputId": "cc720a9e-27a0-4f7a-ff45-1850bf934b8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [2, 3], [4], [5, 6, 7], [8], [9, 10], [11, 12], [13], [14, 15, 16, 17], [18], [19], [20], [21], [21], [21], [21], [22], [23, 21], [19], [23, 24, 21], [19], [19], [19], [19], [19], [19], [25, 26, 27], [21], [28, 29, 21, 30], [21], [31], [23], [21], [32, 33, 34, 35, 36], [37, 38], [39, 40], [41], [37], [39, 40], [21], [23, 21], [41], [39], [21], [42, 43, 44, 23, 45], [23, 21], [23, 21], [21], [21], [46, 47, 48, 49], [37, 50], [21], [21], [51], [52, 53, 54], [31], [31], [31], [55], [41], [56], [57], [58, 59, 60], [41], [61, 56], [62, 63], [51, 64], [37, 38], [65], [66, 67], [57], [57], [68, 69, 70, 71, 72, 73], [74], [74], [31], [75, 76], [77, 78, 79], [21], [75, 76], [80], [81], [82, 83, 84, 85, 86, 87, 88], [75, 76], [31], [89], [90], [91, 92], [38], [93, 94, 95], [21], [74], [21, 96, 43, 97], [62, 63, 98, 99], [79], [79], [21], [31], [31], [100], [79], [61], [101, 102, 103, 104, 105, 106, 107], [21], [108, 109], [79], [110, 111, 112, 91], [37], [102], [21], [19], [21, 113, 43, 114, 115], [116, 117], [118], [119, 120, 121], [21], [122, 123, 124, 41, 125], [126], [127, 128, 129, 130, 131, 132, 133, 134], [98, 62, 135, 63, 136, 137], [21, 138, 23, 139], [102, 123, 140], [141, 142], [114, 143, 144, 145], [114], [146, 147], [148, 149, 150, 151, 152, 153, 154, 155], [156, 157], [158], [159, 160, 161, 162, 163, 164, 165], [166, 167, 168, 169, 170, 171, 172, 173], [174, 175, 176, 177, 178, 179], [140, 125], [158], [180, 181], [182, 183], [180, 184, 185, 181], [186, 149, 154, 187], [188], [181, 180, 189], [185], [122, 190], [41], [191, 181, 189], [180, 181, 185], [192, 193, 194, 195, 196, 197, 198, 199], [200, 201], [202, 200, 201, 203], [21], [189, 185], [204, 205, 206, 207], [208, 21], [181, 189], [209], [102], [210], [211, 212, 213, 214], [185, 215, 216, 181, 189, 217, 218], [219], [220], [191, 181, 189, 221, 185, 222], [223, 224], [225, 226, 227, 228], [181, 189, 221, 229, 230], [181, 189, 221, 185, 231], [216, 181, 189, 185, 229, 232], [157], [21], [233, 181, 234], [235, 236, 182], [233, 181, 237, 238], [41], [185], [239, 223, 224], [240, 241], [200], [242, 243, 244, 245], [236, 182, 183], [246, 247, 248, 249, 250, 251, 252], [253, 254, 255, 256, 257, 258], [157], [259, 260, 261, 262, 263, 264], [185, 221, 181, 216], [265, 266, 267, 268], [181], [269, 270], [271, 272, 273, 240, 274], [275], [224], [276, 277, 224, 278], [279, 239, 280, 281, 282], [239, 281, 283, 278, 280], [245], [284, 158, 285, 286, 287, 288, 289], [122, 290, 283, 190, 291, 292, 293], [211], [294, 295, 296, 297], [298, 239, 299, 276, 277, 223, 281], [277, 239, 276, 223], [300, 301, 298, 278, 283, 280, 239, 302], [303, 239, 301, 277, 223, 279, 304, 278], [281, 239, 298, 278, 279, 283], [305, 306, 307], [304, 283, 280, 308, 301, 223, 281, 309], [304, 283, 278, 239, 308, 211, 301], [310, 311], [276, 301, 277, 224, 304], [276, 223], [312, 313], [223, 276], [224, 278, 239, 281, 301, 314, 223], [279, 281, 278, 283, 301, 314, 315], [316, 317, 318, 319, 320, 321, 289, 322], [277, 276], [298, 283, 323, 281, 314, 280, 301, 279], [21], [276, 239, 277], [304, 283, 239, 314, 301, 223, 279, 324], [325, 326, 327, 328], [304, 279, 283, 278, 239, 301, 223, 324], [247, 329], [330, 331, 332, 160, 333, 277], [158, 334], [182], [278, 335, 301, 279, 283, 304, 324], [158, 336, 240, 337, 289, 322], [338], [339, 158], [290, 312, 313, 340], [341, 342, 343, 344], [276, 277], [278, 277, 224], [324, 301, 278, 239, 299, 315, 298], [283, 304, 278, 301, 239, 345, 315, 281], [346, 278, 239, 279, 223, 301, 298], [275], [278, 301, 315, 281], [281, 278, 301, 239, 315, 279], [347], [348, 349, 350], [304, 281, 278, 211, 301, 279, 283, 351], [352, 351, 279, 298, 281, 239, 308], [149, 328, 353, 187], [304, 279, 354, 301, 281, 355, 356], [283, 301, 277, 309, 304, 278], [223, 357, 239, 358, 278, 279, 345, 301], [277, 223], [276], [276, 211, 277, 359, 224, 278], [351, 281, 278, 283, 301, 239, 279], [279, 283, 301, 356], [276, 277, 224, 304], [360, 361, 290, 190], [278, 276, 299, 277, 301], [278, 277, 239, 224], [277, 239, 304], [290, 275], [102], [276, 352, 224], [340, 190, 362, 122, 360, 363, 283], [301, 239, 281, 278], [276, 277, 301, 211, 224, 304], [167, 166], [364, 365, 366, 367, 368, 369], [370, 190, 340, 290, 122], [276, 223], [224, 314, 278, 276, 301, 223, 371], [281, 278, 301, 279, 283, 324, 304], [324, 314, 283, 304, 301, 281, 279], [372, 314, 283, 324, 357, 239, 224], [277], [276, 277, 304], [190, 370, 373, 122, 374, 291, 375, 376], [276], [377, 299, 276, 304, 224, 378, 379], [380], [309, 301, 239, 281, 279, 283], [279, 335, 278, 283, 301, 239, 281], [277, 276, 239], [223, 224, 277], [278, 283, 304, 276], [224, 283, 281, 239, 381, 301, 279], [281, 382, 239, 301, 278], [383, 384, 277, 385], [278, 190, 299, 290, 370, 386, 283, 122], [247, 248, 246, 249], [387, 283, 301, 280, 314, 359, 281, 279], [276, 211], [360, 122, 283, 374, 388, 362, 291, 389], [299, 276, 277, 224, 304, 278], [299, 190], [390, 391, 181, 189], [181, 391], [181, 392, 391, 393], [387, 314, 283, 239, 301, 223, 279, 309], [299, 223], [301, 283, 239, 223, 304, 278], [304, 277, 276, 239, 211, 301, 224], [275], [278, 283, 239, 280, 301, 314, 281], [391, 181, 189, 218, 229, 222, 232], [21], [283, 279, 239, 278], [301, 276, 299, 298, 278, 394], [298, 279, 283, 278, 301, 239, 223, 281], [224, 276, 211, 223, 304, 278], [177, 395], [396, 397, 398, 399], [312, 340], [283, 304, 279, 223, 345, 301, 359], [283, 281, 278, 239, 280]]\n"
     ]
    }
   ],
   "source": [
    "loaded = json.load(open(\"preprocessed.json\", encoding=\"utf-8\"))\n",
    "print(loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LYf8LEHnjVRt",
    "outputId": "08d9c00c-0d35-41a7-a72c-e706faf256da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
      "name                      size  creationDate         \n",
      "-----------------------  -----  -------------------  \n",
      "title.ratings.tsv.gz       5MB  2019-11-18 18:36:47  \n",
      "title.akas.tsv.gz        158MB  2019-11-18 18:36:47  \n",
      "title.basics.tsv.gz      108MB  2019-11-18 18:36:47  \n",
      "title.principals.tsv.gz  290MB  2019-11-18 18:36:47  \n",
      "name.basics.tsv.gz       180MB  2019-11-18 18:36:47  \n",
      "Downloading title.principals.tsv.gz.zip to /content\n",
      " 98% 282M/287M [00:03<00:00, 99.1MB/s]\n",
      "100% 287M/287M [00:03<00:00, 94.8MB/s]\n",
      "Archive:  title.principals.tsv.gz.zip\n",
      "  inflating: title.principals.tsv.gz  \n"
     ]
    }
   ],
   "source": [
    "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# !wget -q https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz    \n",
    "# !tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
    "# !pip3 install -q findspark\n",
    "# !pip3 install -q pyspark\n",
    "# !pip3 install -q kaggle\n",
    "\n",
    "# from google.colab import files\n",
    "# files.upload()\n",
    "# !mkdir -p ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !ls ~/.kaggle\n",
    "# !chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "# print(\"Upload sample file\")\n",
    "# files.upload()\n",
    "!kaggle datasets files \"ashirwadsangwan/imdb-dataset\"\n",
    "!kaggle datasets download \"ashirwadsangwan/imdb-dataset\" -f \"title.principals.tsv.gz\"\n",
    "!unzip \"title.principals.tsv.gz.zip\"\n",
    "!rm \"title.principals.tsv.gz.zip\"\n",
    "!gunzip -k \"title.principals.tsv.gz\"\n",
    "!rm \"title.principals.tsv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CRV-pFU7nl8Q"
   },
   "outputs": [],
   "source": [
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
    "\n",
    "home = os.environ[\"SPARK_HOME\"]\n",
    "os.environ[\"PYTHONPATH\"] = home+\"/python\"+home+\"/python/lib/py4j-0.10.9-src.zip:\"+os.environ[\"PYTHONPATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nj2Stk8SjVRu"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ImqZKjluxmRC"
   },
   "outputs": [],
   "source": [
    "sourceFile = 'title.principals.tsv'\n",
    "\n",
    "data = spark.read.options(delimiter = \";\", header=True).csv(sourceFile)\n",
    "\n",
    "rdd_result = data.rdd.map(lambda row: (row[\"nconst\"], 0) if row[\"category\"] == 'actress' or row[\"category\"] == 'actor' else (-1, 0))\\\n",
    "                 .reduceByKey(lambda a, b: 0)\\\n",
    "                 .filter(lambda x: x[0] != -1)\n",
    "res = rdd_result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PNx2es-PyJjG"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(spark)\n",
    "df = sqlContext.createDataFrame(res, ['item', 'value']).select('item')\n",
    "df.coalesce(1).write.format('com.databricks.spark.csv').save(\"folder.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "wg9C8d_468yJ"
   },
   "outputs": [],
   "source": [
    "!mv folder.csv/*.csv actorIdToInt.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nJU7dJnP1i-f"
   },
   "outputs": [],
   "source": [
    "!rm -rf actorIdToInt.csv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikFnITsQxnJD"
   },
   "source": [
    "Create preprocessed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUbdH6a5jVRv",
    "outputId": "8d36b722-9142-44a2-f06c-d31c41d6a825"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourceFile = 'title.principals.tsv'\n",
    "\n",
    "data = spark.read.options(delimiter = \";\", header=True).csv(sourceFile)\n",
    "\n",
    "#Get a list of actorIDs, their position is the encoding\n",
    "actorToId = [el._c0 for el in spark.read.options(delimiter = \";\", header=False).csv(\"actorIdToInt.csv\").collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "2OIEKc7VtoOs"
   },
   "outputs": [],
   "source": [
    "filter_actors = lambda row: (row[\"tconst\"], [actorToId.index(row[\"nconst\"])]) if row[\"category\"] == 'actress' or row[\"category\"] == 'actor' else (-1,[])\n",
    "rdd_result = data.rdd.map(filter_actors).reduceByKey(lambda a, b: a + b).filter(lambda x: x[0] != -1).values()\n",
    "res = rdd_result.collect()\n",
    "with open('preprocessed.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=\";\")\n",
    "    writer.writerows(res)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
