{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from bitmap import BitMap\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[2, 3]\n",
      "[4]\n",
      "[5, 6, 7]\n",
      "[8]\n",
      "[9, 10]\n",
      "############\n",
      "[0, 1]\n",
      "[2, 3]\n",
      "[4]\n",
      "[5, 6, 7]\n",
      "[8]\n",
      "[9, 10]\n"
     ]
    }
   ],
   "source": [
    "file = open(\"preprocessed.csv\", encoding=\"utf-8\", newline=\"\\n\")\n",
    "dt = csv.reader(file, delimiter=\";\")\n",
    "c = 5\n",
    "for row in dt:\n",
    "    print(list(map(int,row)))\n",
    "    if c == 0:\n",
    "        break\n",
    "    c -= 1\n",
    "file.close()\n",
    "print(\"############\")\n",
    "file = open(\"preprocessed.csv\", encoding=\"utf-8\", newline=\"\\n\")\n",
    "dt = csv.reader(file, delimiter=\";\")\n",
    "c = 5\n",
    "for row in dt:\n",
    "    row = list(map(int,row))\n",
    "    print(row)\n",
    "    if c == 0:\n",
    "        break\n",
    "    c -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phase 1 scan all baskets \n",
    "# -input: id_movie, list(int_actor)\n",
    "# -compute frequency (count)\n",
    "# -count combinations (size 2) into hashmap\n",
    "# -filter frequent singletons (count >= s)\n",
    "# -output: int_actor: count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = json.load(open(\"preprocessed.json\", encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data(file):\n",
    "    return csv.reader(open(file, encoding=\"utf-8\", newline=\"\\n\"), delimiter=\";\")\n",
    "\n",
    "def hashF(element, size):\n",
    "    return hash(element)%size\n",
    "\n",
    "def get_combinations(basket, size):\n",
    "    return it.combinations(sorted(basket), size)\n",
    "\n",
    "def update_frequency(l, item):\n",
    "    if item + 1 > len(l):\n",
    "        l.extend((item+1-len(l))*[0])\n",
    "    l[item] += 1\n",
    "    \n",
    "def singleton_pairs_frequency(filename, hash_size, threshold):\n",
    "    singleton_freq = []\n",
    "    hashmap = np.zeros(hash_size)\n",
    "    for basket in open_data(filename):\n",
    "        basket = list(map(int, basket))\n",
    "        for item in basket:\n",
    "            update_frequency(singleton_freq, item)\n",
    "        for pair in get_combinations(basket, 2):\n",
    "            hashmap[hashF(pair, hash_size)] += 1\n",
    "    return filter_singletons(singleton_freq, threshold), hashmap\n",
    "\n",
    "# this function filter the given singletons with the absolute freqeuncy, deleting the ones with\n",
    "# frequency below the threshold\n",
    "def filter_singletons(singleton, threshold):\n",
    "    return [(iid,) for iid, freq in enumerate(singleton) if freq>threshold]    \n",
    "\n",
    "# this function collapse the hashmap given in input into a bitmap of size \"size\" and set a 1 in the bitmap if the value in\n",
    "# the hashmap is over the the given threshold\n",
    "def hash_to_bitmap(hashmap, size, threshold):\n",
    "    bmap = BitMap(size)\n",
    "    for position in range(len(hashmap)):\n",
    "        if hashmap[position] >= threshold:\n",
    "            bmap.set(position)\n",
    "    del hashmap\n",
    "    return bmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phase 3\n",
    "# -scan all baskets to remove FP:\n",
    "# ---read all baskets: for each basket compute pairs with 1 in bitmap\n",
    "# ---for each couple compute frequency\n",
    "# ---filter each couple (count > s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute every pairs of frequent singletons\n",
    "# if the hash of a pair indicates a position in bitmap with \"1\", check how many times it appears in baskets\n",
    "# otehrwise not consider this pair\n",
    "# generare coppie dai singleton, filtrarle per chi ha 1 nella bitmap, cercare in data solo quelli sopravvissuti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the k-th step, meanwhile creating the hashmap counter for the k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joins(tuples, k):\n",
    "    #implement join in this way\n",
    "    #to obtain an element of lenght k:\n",
    "    #join 2 elements of length k-1 with the first k-1 elements in common\n",
    "    l = []\n",
    "    for i in range(len(tuples)-1):\n",
    "        for j in range(i+1, len(tuples)):\n",
    "            if(tuples[i][:k-2] == tuples[j][:k-2]):\n",
    "                l += [tuples[i] + tuples[j][k-2:]]\n",
    "    return l\n",
    "\n",
    "def get_kth(filename, precedents, hash_size, bmap, threshold, k):\n",
    "#     tuple of length k with corresponding bitmap value = 1\n",
    "    kth = [tpl for tpl in get_joins(precedents, k) if bmap[hashF(tpl, hash_size)]]\n",
    "    \n",
    "#     counts the absolute frequency of the tuple in kth\n",
    "    counters = np.zeros(len(kth))\n",
    "#     hashmap for the tuples of length k+1\n",
    "    next_hashmap = np.zeros(hash_size)\n",
    "    \n",
    "    for basket in open_data(filename):\n",
    "        basket = list(map(int, basket))\n",
    "        tpls = list(get_combinations(basket, k))\n",
    "        for i in range(len(kth)):\n",
    "            if kth[i] in tpls:\n",
    "                counters[i] += 1\n",
    "        for kth_tuples in get_combinations(basket, k+1):\n",
    "            next_hashmap[hashF(kth_tuples, hash_size)] += 1\n",
    "\n",
    "    return [kth[i] for i in range(len(kth)) if counters[i]>=threshold], next_hashmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found frequent itemset of length:  1\n",
      "Found frequent itemset of length:  2\n",
      "Found frequent itemset of length:  3\n",
      "Found frequent itemset of length:  4\n"
     ]
    }
   ],
   "source": [
    "def main(filename, threshold, hash_size):\n",
    "    frequent_sets = []\n",
    "#     phase 1: compute frequency of singletons and pairs; filter nonfrequent singletons\n",
    "    singleton, hashmap = singleton_pairs_frequency(filename, hash_size, threshold)\n",
    "#     phase 2: collpse the hahsmap into a bitmap\n",
    "    bitmap = hash_to_bitmap(hashmap, hash_size, threshold)\n",
    "#     phase 3\n",
    "#     frequent_sets contains all the sets of all the kth length that are frequent\n",
    "#     bitmap is the bitmap mapping the sets of length k+1\n",
    "#     frequent_sets, bitmap = frequent_couple(data, singleton, hash_size, bitmap, threshold)\n",
    "    frequent_sets += singleton\n",
    "    print(\"Found frequent itemset of length: \",1)\n",
    "    k = 2\n",
    "    result = [\"placeholder\"]\n",
    "    while result != []:\n",
    "        precedents = [i for i in frequent_sets if len(i) == k-1 ]\n",
    "        result, hashmap = get_kth(filename, precedents, hash_size, bitmap, threshold, k)\n",
    "        bitmap = hash_to_bitmap(hashmap, hash_size, threshold)\n",
    "        frequent_sets = frequent_sets + result\n",
    "        print(\"Found frequent itemset of length: \",k)\n",
    "        k += 1\n",
    "        \n",
    "    return frequent_sets\n",
    "\n",
    "filename = \"preprocessed.csv\"\n",
    "freq_sets = main(filename, 15, 504)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv = csv.reader(open('actorIdToInt.csv', newline='\\n'), delimiter='\\n')\n",
    "actorIds = []\n",
    "for row in csv:\n",
    "    actorIds.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Georges Méliès']\n",
      "['Viggo Larsen']\n",
      "['Robert Harron']\n",
      "[\"Anthony O'Sullivan\"]\n",
      "['Linda Arvidson']\n",
      "['Edward Dillon']\n",
      "['D.W. Griffith']\n",
      "['Harry Solter']\n",
      "['Arthur V. Johnson']\n",
      "['Charles Inslee']\n",
      "['Florence Lawrence']\n",
      "['George Gebhardt']\n",
      "['Mack Sennett']\n",
      "['Linda Arvidson', 'Harry Solter']\n",
      "['Linda Arvidson', 'Arthur V. Johnson']\n",
      "['Linda Arvidson', 'Charles Inslee']\n",
      "['Linda Arvidson', 'Florence Lawrence']\n",
      "['Linda Arvidson', 'George Gebhardt']\n",
      "['D.W. Griffith', 'Edward Dillon']\n",
      "['Charles Inslee', 'Harry Solter']\n",
      "['Florence Lawrence', 'Harry Solter']\n",
      "['George Gebhardt', 'Harry Solter']\n",
      "['Charles Inslee', 'Arthur V. Johnson']\n",
      "['Arthur V. Johnson', 'Florence Lawrence']\n",
      "['George Gebhardt', 'Arthur V. Johnson']\n",
      "['Charles Inslee', 'Florence Lawrence']\n",
      "['George Gebhardt', 'Charles Inslee']\n",
      "['George Gebhardt', 'Florence Lawrence']\n",
      "['George Gebhardt', 'Mack Sennett']\n",
      "['Linda Arvidson', 'George Gebhardt', 'Harry Solter']\n",
      "['George Gebhardt', 'Arthur V. Johnson', 'Florence Lawrence']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "def intToItem(integers, actorIds):\n",
    "    counter = 0\n",
    "    ids = [tuple([actorIds[item] for item in couple]) for couple in integers]\n",
    "    #total actors in ids, with repetition\n",
    "    for el in ids:\n",
    "        counter += len(el)\n",
    "    translated = [[]]*len(ids)\n",
    "    \n",
    "    c = 2\n",
    "    tsv = csv.reader(open(\"name.tsv\", encoding=\"utf-8\"), delimiter=\"\\t\")\n",
    "    for row in tsv:\n",
    "        for pos in range(len(ids)):\n",
    "            if row[0] in ids[pos]:\n",
    "                translated[pos] = translated[pos] + [row[1]]\n",
    "                counter -= 1\n",
    "        if counter == 0:\n",
    "            break\n",
    "    return translated\n",
    "\n",
    "for el in intToItem(freq_sets, actorIds):\n",
    "    print(el)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
