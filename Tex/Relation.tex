\documentclass[14pt]{extarticle}
\usepackage[left=3cm, right=3cm]{geometry}
\usepackage{amsmath, amssymb}
\usepackage{nccmath}
\usepackage{amsthm}
\usepackage{comment}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage[math]{cellspace}
    \cellspacetoplimit 4pt
    \cellspacebottomlimit 4pt
\usepackage{titletoc}
\usepackage{float}
\usepackage[ruled,longend]{algorithm2e}
\usepackage{imakeidx}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=blue,
    linktoc=all
}

\linespread{1.2}
\title{{\Huge Market Basket Analysis}\\{\Large Master in Data Science}}
\bigskip
\author{\bigskip \\ \bigskip{\Large Alberto Bertoncini 983833}\\ \smallskip{\Large Massimo Cavagna 9838??}\\ \bigskip \href{https://github.com/Bertonc98/ProgettoAMD}{Github repository} }

\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage
\section{Introduction}
The purpose of this paper is to present some of the techniques used in order to perform the so called "market/basket" analysis for a huge amount of data.
At first these techniques were exploited for the analysis of purchases in markets, trying to find some relationships among the goods bought by customers.
The idea behind these algorithms is to find associations between goods so that can be claimed that if a customer buy item A he is also likely to buy item B and vice versa.
This concept could be extended to association between sets of goods (not only single item pairs) and to generic items instead of just goods, so that,  in the end, the aim of the algorithms that will be presented is to find frequent sets of items in all the baskets available.
In particular, three main algorithms will be implemented:
\begin{itemize}
\item[-] A-priori:
\vspace{-0.4cm}\begin{itemize}
\item[-] base
\vspace{-0.2cm}\item[-] PCY
\end{itemize}
\vspace{-0.4cm}\item[-] SON
\vspace{-0.4cm}\item[-] Toivonen
\end{itemize}
Once the frequents sets are found, it is also important to check if all the items in one of these sets are actually associated one another:
indeed, considering the environment these techniques come from, we could find that some goods, such as "milk" or "bread" are always frequent, but it cannot be claimed that there is a actual relationship with all the other items in the same frequent set, since it will be bought independently from the other.
\section{Dataset}
\section{Data structure}
\section{Preprocessing}
\section{Algorithms applied}
\section{Scaling of proposed solutions}
\section{Experiments}
\section{Results}
{\it I/We declare that this material, which I/We now submit for assessment, is entirely my/our own work and has not been taken from the work of others, save and to the extent that such work has been cited and acknowledged within the text of my/our work. I/We understand that plagiarism, collusion, and copying are grave and serious offences in the university and accept the penalties that would be imposed should I engage in plagiarism, collusion or copying. This assignment, or any part of it, has not been previously submitted by me/us or any other person for assessment on this or any other course of study.}
\begin{comment}
The report should contain the following information:

-the chosen dataset, and the parts of the latter which have been considered,
-how data have been organized,
-the applied pre-processing techniques,
-the considered algorithms and their implementations,
-how the proposed solution scales up with data size,
-a description of the experiments,
-comments and discussion on the experimental results.

\end{comment}
\end{document}

